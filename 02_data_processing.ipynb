{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing\n",
    "===\n",
    "> Handles the processing, including encoding of attributes, creation of sliding windows, adding of start and end events, generation of data loaders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Column-renaming-and-adding-of-start-and-end-events\" data-toc-modified-id=\"Column-renaming-and-adding-of-start-and-end-events-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Column renaming and adding of start and end events</a></span></li><li><span><a href=\"#Trace-Splitting\" data-toc-modified-id=\"Trace-Splitting-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Trace Splitting</a></span></li><li><span><a href=\"#Encoding-Techniques\" data-toc-modified-id=\"Encoding-Techniques-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Encoding Techniques</a></span><ul class=\"toc-item\"><li><span><a href=\"#PPObj\" data-toc-modified-id=\"PPObj-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>PPObj</a></span></li><li><span><a href=\"#Categorization\" data-toc-modified-id=\"Categorization-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Categorization</a></span></li><li><span><a href=\"#Fill-Missing\" data-toc-modified-id=\"Fill-Missing-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Fill Missing</a></span></li><li><span><a href=\"#Z-score\" data-toc-modified-id=\"Z-score-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Z-score</a></span></li><li><span><a href=\"#Date-conversion\" data-toc-modified-id=\"Date-conversion-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Date conversion</a></span></li><li><span><a href=\"#MinMax-Scaling\" data-toc-modified-id=\"MinMax-Scaling-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>MinMax Scaling</a></span></li><li><span><a href=\"#One-HoT-Encoding\" data-toc-modified-id=\"One-HoT-Encoding-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>One HoT Encoding</a></span></li></ul></li><li><span><a href=\"#Window-Generation\" data-toc-modified-id=\"Window-Generation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Window Generation</a></span></li><li><span><a href=\"#Data-Loader\" data-toc-modified-id=\"Data-Loader-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Data Loader</a></span><ul class=\"toc-item\"><li><span><a href=\"#Integration-Samples\" data-toc-modified-id=\"Integration-Samples-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Integration Samples</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from dapnn.imports import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 02_data_processing.ipynb.\n"
     ]
    }
   ],
   "source": [
    "notebook2script(fname='02_data_processing.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column renaming and adding of start and end events\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def df_preproc (df,cols=['activity'],start_marker='###start###',end_marker='###end###'):\n",
    "    # Add event log column\n",
    "    df['event_id']=df.groupby('trace_id').cumcount()+1    \n",
    "    # Work with numpy for performance boost\n",
    "    eid_col = df.columns.to_list().index('event_id')\n",
    "       \n",
    "    # Get col idx\n",
    "    col_idx=[df.columns.to_list().index(c) for c in cols]\n",
    "        \n",
    "    data= df.values\n",
    "    # Add Start Events\n",
    "    idx= np.where(data[:,eid_col]==1)[0] # start idx\n",
    "    new = data[idx].copy()\n",
    "    \n",
    "    for c in col_idx: new[:,c]=start_marker\n",
    "    new[:,eid_col]=0\n",
    "    data = np.insert(data,idx,new, axis=0)\n",
    "    # Add End Events\n",
    "    idx= np.where(data[:,eid_col]==0)[0][1:] # start idx without the first\n",
    "    new = data[idx-1].copy() # get data from current last idx\n",
    "    for c in col_idx: new[:,c]=end_marker\n",
    "    \n",
    "    new[:,eid_col]=new[:,eid_col]+1\n",
    "    data = np.insert(data,idx,new, axis=0)\n",
    "    # take care of final last event\n",
    "    last= data[-1].copy()\n",
    "    for c in col_idx: last[c]=end_marker\n",
    "\n",
    "    last[eid_col]+=1\n",
    "    data = np.insert(data,len(data),last, axis=0)\n",
    "    df = pd.DataFrame(data,columns=df.columns)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn='data/csv/binet_logs/medium-0.3-4.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>timestamp_end</th>\n",
       "      <th>anomaly</th>\n",
       "      <th>trace_id</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>day</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Activity A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rework</td>\n",
       "      <td>1</td>\n",
       "      <td>Codehow</td>\n",
       "      <td>Comoros</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Wilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Activity Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rework</td>\n",
       "      <td>1</td>\n",
       "      <td>Plussunin</td>\n",
       "      <td>Chad</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Iluminada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     activity  timestamp  timestamp_end anomaly  trace_id    company  country  \\\n",
       "0  Activity A        NaN            NaN  Rework         1    Codehow  Comoros   \n",
       "1  Activity Z        NaN            NaN  Rework         1  Plussunin     Chad   \n",
       "\n",
       "         day       user  \n",
       "0  Wednesday     Wilton  \n",
       "1    Tuesday  Iluminada  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(fn)\n",
    "df.rename({'name':'activity','case:concept:name':'trace_id'},axis=1,inplace=True)\n",
    "if not 'activity' in df.columns:\n",
    "    df.rename({'concept:name':'activity'},axis=1,inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.2 ms, sys: 14 Âµs, total: 24.3 ms\n",
      "Wall time: 23.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df1 =df_preproc(df,cols=['activity','company','country','day','user'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Start and End event, and rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def import_log(log_path,cols=['activity']):\n",
    "    df=pd.read_csv(log_path)\n",
    "    df.rename({'name':'activity','case:concept:name':'trace_id'},axis=1,inplace=True)\n",
    "    if not 'activity' in df.columns:\n",
    "        df.rename({'concept:name':'activity'},axis=1,inplace=True)\n",
    "    df.rename({'case:pdc:isPos':'normal'},axis=1,inplace=True)\n",
    "    df = df_preproc(df,cols)\n",
    "    df.index=df.trace_id\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>trace_id</th>\n",
       "      <th>case:pdc:costs</th>\n",
       "      <th>normal</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>###start###</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t11</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t21</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t26</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t35</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t41</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t51</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t61</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t44</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t71</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t81</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t54</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t65</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t76</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t82</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t91</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>###end###</td>\n",
       "      <td>trace 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>###start###</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>t11</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>t26</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>t35</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>t21</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>t32</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>t44</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>t54</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>t41</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>t65</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>t76</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>t51</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>t62</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>t82</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>t71</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>t81</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>t91</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 2</th>\n",
       "      <td>###end###</td>\n",
       "      <td>trace 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             activity trace_id case:pdc:costs normal event_id\n",
       "trace_id                                                     \n",
       "trace 1   ###start###  trace 1            2.0  False        0\n",
       "trace 1           t11  trace 1            2.0  False        1\n",
       "trace 1           t21  trace 1            2.0  False        2\n",
       "trace 1           t26  trace 1            2.0  False        3\n",
       "trace 1           t35  trace 1            2.0  False        4\n",
       "trace 1           t41  trace 1            2.0  False        5\n",
       "trace 1           t51  trace 1            2.0  False        6\n",
       "trace 1           t61  trace 1            2.0  False        7\n",
       "trace 1           t44  trace 1            2.0  False        8\n",
       "trace 1           t71  trace 1            2.0  False        9\n",
       "trace 1           t81  trace 1            2.0  False       10\n",
       "trace 1           t54  trace 1            2.0  False       11\n",
       "trace 1           t65  trace 1            2.0  False       12\n",
       "trace 1           t76  trace 1            2.0  False       13\n",
       "trace 1           t82  trace 1            2.0  False       14\n",
       "trace 1           t91  trace 1            2.0  False       15\n",
       "trace 1     ###end###  trace 1            2.0  False       16\n",
       "trace 2   ###start###  trace 2            0.0   True        0\n",
       "trace 2           t11  trace 2            0.0   True        1\n",
       "trace 2           t26  trace 2            0.0   True        2\n",
       "trace 2           t35  trace 2            0.0   True        3\n",
       "trace 2           t21  trace 2            0.0   True        4\n",
       "trace 2           t32  trace 2            0.0   True        5\n",
       "trace 2           t44  trace 2            0.0   True        6\n",
       "trace 2           t54  trace 2            0.0   True        7\n",
       "trace 2           t41  trace 2            0.0   True        8\n",
       "trace 2           t65  trace 2            0.0   True        9\n",
       "trace 2           t76  trace 2            0.0   True       10\n",
       "trace 2           t51  trace 2            0.0   True       11\n",
       "trace 2           t62  trace 2            0.0   True       12\n",
       "trace 2           t82  trace 2            0.0   True       13\n",
       "trace 2           t71  trace 2            0.0   True       14\n",
       "trace 2           t81  trace 2            0.0   True       15\n",
       "trace 2           t91  trace 2            0.0   True       16\n",
       "trace 2     ###end###  trace 2            0.0   True       17"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = import_log('data/csv/PDC2020_ground_truth/pdc_2020_0000000.csv.gz')\n",
    "log[:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>timestamp_end</th>\n",
       "      <th>anomaly</th>\n",
       "      <th>trace_id</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>day</th>\n",
       "      <th>user</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>###start###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rework</td>\n",
       "      <td>1</td>\n",
       "      <td>###start###</td>\n",
       "      <td>###start###</td>\n",
       "      <td>###start###</td>\n",
       "      <td>###start###</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Activity A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rework</td>\n",
       "      <td>1</td>\n",
       "      <td>Codehow</td>\n",
       "      <td>Comoros</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Wilton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Activity Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rework</td>\n",
       "      <td>1</td>\n",
       "      <td>Plussunin</td>\n",
       "      <td>Chad</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Iluminada</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Activity AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rework</td>\n",
       "      <td>1</td>\n",
       "      <td>year-job</td>\n",
       "      <td>Libyan Arab Jamahiriya</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Sandra</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Activity AF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rework</td>\n",
       "      <td>1</td>\n",
       "      <td>Donquadtech</td>\n",
       "      <td>Cocos (Keeling) Islands</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Ling</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>Activity W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>5000</td>\n",
       "      <td>year-job</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Jimmy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>Activity V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>5000</td>\n",
       "      <td>Openlane</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Deloras</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>Activity P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>5000</td>\n",
       "      <td>Lexiqvolax</td>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Rossana</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>Activity B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>5000</td>\n",
       "      <td>Y-corporation</td>\n",
       "      <td>Heard Island &amp; Mcdonald Islands</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Della</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>###end###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>5000</td>\n",
       "      <td>###end###</td>\n",
       "      <td>###end###</td>\n",
       "      <td>###end###</td>\n",
       "      <td>###end###</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39881 rows Ã 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             activity timestamp timestamp_end anomaly trace_id        company  \\\n",
       "trace_id                                                                        \n",
       "1         ###start###       NaN           NaN  Rework        1    ###start###   \n",
       "1          Activity A       NaN           NaN  Rework        1        Codehow   \n",
       "1          Activity Z       NaN           NaN  Rework        1      Plussunin   \n",
       "1         Activity AA       NaN           NaN  Rework        1       year-job   \n",
       "1         Activity AF       NaN           NaN  Rework        1    Donquadtech   \n",
       "...               ...       ...           ...     ...      ...            ...   \n",
       "5000       Activity W       NaN           NaN  normal     5000       year-job   \n",
       "5000       Activity V       NaN           NaN  normal     5000       Openlane   \n",
       "5000       Activity P       NaN           NaN  normal     5000     Lexiqvolax   \n",
       "5000       Activity B       NaN           NaN  normal     5000  Y-corporation   \n",
       "5000        ###end###       NaN           NaN  normal     5000      ###end###   \n",
       "\n",
       "                                  country          day         user event_id  \n",
       "trace_id                                                                      \n",
       "1                             ###start###  ###start###  ###start###        0  \n",
       "1                                 Comoros    Wednesday       Wilton        1  \n",
       "1                                    Chad      Tuesday    Iluminada        2  \n",
       "1                  Libyan Arab Jamahiriya    Wednesday       Sandra        3  \n",
       "1                 Cocos (Keeling) Islands       Friday         Ling        4  \n",
       "...                                   ...          ...          ...      ...  \n",
       "5000                            Indonesia       Monday        Jimmy        4  \n",
       "5000                            Australia      Tuesday      Deloras        5  \n",
       "5000                           Uzbekistan    Wednesday      Rossana        6  \n",
       "5000      Heard Island & Mcdonald Islands      Tuesday        Della        7  \n",
       "5000                            ###end###    ###end###    ###end###        8  \n",
       "\n",
       "[39881 rows x 10 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_log(fn,['activity','company','country','day','user'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace Splitting\n",
    "i.e. splitting in training, validation and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `split_traces` function is used to split an event_log into training, validation and test set. Furthermore, it removes traces that are longer than a specific threshhold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def drop_long_traces(df,max_trace_len=64,event_id='event_id'):\n",
    "    df=df.drop(np.unique(df[df[event_id]>max_trace_len].index))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def RandomTraceSplitter(split_pct=0.2, seed=None):\n",
    "    \"Create function that splits `items` between train/val with `valid_pct` randomly.\"\n",
    "    def _inner(trace_ids):\n",
    "        o=np.unique(trace_ids)\n",
    "        np.random.seed(seed)\n",
    "        rand_idx = np.random.permutation(o)\n",
    "        cut = int(split_pct * len(o))\n",
    "        return L(rand_idx[cut:].tolist()),L(rand_idx[:cut].tolist())\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def split_traces(df,df_name='tmp',test_seed=42,validation_seed=None):\n",
    "    \n",
    "    df=drop_long_traces(df)\n",
    "    ts=RandomTraceSplitter(seed=test_seed)\n",
    "    train,test=ts(df.index)\n",
    "    ts=RandomTraceSplitter(seed=validation_seed,split_pct=0.1)\n",
    "    train,valid=ts(train)\n",
    "    return train,valid,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "a1,b1,c1=split_traces(log)\n",
    "a2,b2,c2=split_traces(log)\n",
    "test_ne(a1,a2),test_ne(b1,b2),test_eq(c1,c2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Techniques\n",
    "Categorization, Normalization, One-Hot, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPObj\n",
    "an object, that manages the pre-processing and knows date columns, cat columns and cont columns\n",
    "with a few convenient functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _TraceIloc:\n",
    "    \"Get/set rows by iloc and cols by name\"\n",
    "    def __init__(self,o): self.o = o\n",
    "    def __getitem__(self, idxs):\n",
    "        df = self.o.items\n",
    "        if isinstance(idxs,tuple):\n",
    "            rows,cols = idxs\n",
    "            rows=df.index[rows]\n",
    "            return self.o.new(df.loc[rows,cols])\n",
    "        else:\n",
    "            rows,cols = idxs,slice(None)\n",
    "            rows=np.unique(df.index)[rows]\n",
    "            return self.o.new(df.loc[rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PPObj(CollBase, GetAttr, FilteredBase):\n",
    "    \"Main Class for Process Prediction\"\n",
    "    _default,with_cont='procs',True\n",
    "    def __init__(self,df,procs=None,cat_names=None,cont_names=None,date_names=None,y_names=None,splits=None,\n",
    "                 ycat_names=None,ycont_names=None,inplace=False,do_setup=True):\n",
    "        if not inplace: df=df.copy()\n",
    "        if splits is not None: df = df.loc[sum(splits, [])] # Can drop traces\n",
    "        self.event_ids=df['event_id'].values if hasattr(df,'event_id') else None\n",
    "\n",
    "        super().__init__(df)\n",
    "\n",
    "        self.cat_names,self.cont_names,self.date_names=(L(cat_names),L(cont_names),L(date_names))\n",
    "        self.set_y_names(y_names,ycat_names,ycont_names)\n",
    "\n",
    "        self.procs = Pipeline(procs)\n",
    "        self.splits=splits\n",
    "        if do_setup: self.setup()\n",
    "\n",
    "\n",
    "    @property\n",
    "    def y_names(self): return self.ycat_names+self.ycont_names\n",
    "\n",
    "    def set_y_names(self,y_names,ycat_names=None,ycont_names=None):\n",
    "        if ycat_names or ycont_names: store_attr('ycat_names,ycont_names')\n",
    "        else:\n",
    "            self.ycat_names,self.ycont_names=(L([i for i in L(y_names) if i in self.cat_names]),\n",
    "                                                L([i for i in L(y_names) if i not in self.cat_names]))\n",
    "    def setup(self): self.procs.setup(self)\n",
    "    def subset(self, i): return self.new(self.loc[self.splits[i]]) if self.splits else self\n",
    "    def __len__(self): return len(np.unique(self.items.index))\n",
    "    def show(self, max_n=3, **kwargs):\n",
    "        print('#traces:',len(self),'#events:',len(self.items))\n",
    "        display_df(self.new(self.all_cols[:max_n]).items)\n",
    "    def new(self, df):\n",
    "        return type(self)(df, do_setup=False,\n",
    "                          **attrdict(self, 'procs','cat_names','cont_names','ycat_names','ycont_names',\n",
    "                                     'date_names'))\n",
    "    def process(self): self.procs(self)\n",
    "    def loc(self): return self.items.loc\n",
    "    def iloc(self): return _TraceIloc(self)\n",
    "    def x_names (self): return self.cat_names + self.cont_names\n",
    "    def all_col_names(self): return ((self.x_names+self.y_names)).unique()\n",
    "    def transform(self, cols, f, all_col=True):\n",
    "        if not all_col: cols = [c for c in cols if c in self.items.columns]\n",
    "        if len(cols) > 0: self[cols] = self[cols].transform(f)\n",
    "    def new_empty(self): return self.new(pd.DataFrame({}, columns=self.items.columns))\n",
    "    def subsets(self): return [self.subset(i) for i in range(len(self.splits))] if self.splits else L(self)\n",
    "properties(PPObj,'loc','iloc','x_names','all_col_names')\n",
    "\n",
    "def _add_prop(cls, nm):\n",
    "    @property\n",
    "    def f(o): return o[list(getattr(o,nm+'_names'))]\n",
    "    @f.setter\n",
    "    def fset(o, v): o[getattr(o,nm+'_names')] = v\n",
    "    setattr(cls, nm+'s', f)\n",
    "    setattr(cls, nm+'s', fset)\n",
    "\n",
    "_add_prop(PPObj, 'cat')\n",
    "_add_prop(PPObj, 'cont')\n",
    "_add_prop(PPObj, 'ycat')\n",
    "_add_prop(PPObj, 'ycont')\n",
    "_add_prop(PPObj, 'y')\n",
    "_add_prop(PPObj, 'x')\n",
    "_add_prop(PPObj, 'all_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppObj=PPObj(log,cat_names=['activity'],y_names=['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) ['activity']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppObj.ycat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 1 #events: 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>t91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 1</th>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ppObj.iloc[0].show(max_n=20) # shows first trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define various pre-processing functions that are executed, when `PPOBj` is instantiated. `PPProc` is the base class for a pre-processing function. It ensures, that setup of a pre-processing function is performed using the training set, and than it is applied to the validation and test set, with the same parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PPProc(InplaceTransform):\n",
    "    \"Base class to write a non-lazy tabular processor for dataframes\"\n",
    "    def setup(self, items=None, train_setup=False): #TODO: properly deal with train_setup\n",
    "        super().setup(getattr(items,'train',items), train_setup=False)\n",
    "        #super().setup(items, train_setup=False)\n",
    "\n",
    "        # Procs are called as soon as data is available\n",
    "        return self(items.items if isinstance(items,Datasets) else items)\n",
    "\n",
    "    @property\n",
    "    def name(self): return f\"{super().name} -- {getattr(self,'__stored_args__',{})}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorization\n",
    "i.e ordinal encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of ordinal or integer encoding. Adds NA values for unknown data. Implementation is pretty much taken from fastai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _apply_cats (voc, add, c):\n",
    "    if not is_categorical_dtype(c):\n",
    "        return pd.Categorical(c, categories=voc[c.name][add:]).codes+add\n",
    "    return c.cat.codes+add #if is_categorical_dtype(c) else c.map(voc[c.name].o2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Categorify(PPProc):\n",
    "    \"Transform the categorical variables to something similar to `pd.Categorical`\"\n",
    "    order = 2\n",
    "    def setups(self, to):\n",
    "        store_attr(classes={n:CategoryMap(to.items.loc[:,n], add_na=True) for n in to.cat_names}, but='to')\n",
    "    def encodes(self, to):\n",
    "        to.transform(to.cat_names, partial(_apply_cats, self.classes, 1))\n",
    "    def __getitem__(self,k): return self.classes[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log=import_log('data/csv/PDC2021_ground_truth/pdc2021_000000.csv.gz')\n",
    "traces=split_traces(log)[0][:100]\n",
    "splits=traces[:60],traces[60:80],traces[80:100]\n",
    "o=PPObj(log,None,cat_names='activity',splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=CategoryMap(o.items.loc[:,'activity'])\n",
    "len(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat=Categorify()\n",
    "cat.setup(o)\n",
    "len(cat['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 5 #events: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'a':[0,1,2,0,2]})\n",
    "to = PPObj(df, Categorify, 'a')\n",
    "to.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 13087 #events: 289892\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log=import_log('data/csv/binet_logs/bpic12-0.3-1.csv.gz')\n",
    "o=PPObj(log,Categorify,'activity')\n",
    "o.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Missing\n",
    "for continuous values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pre-processing function that deals with missing data in continuous attributes. Missing data can be replaced with the median, mean or a constant value. Additionaly, we can create another boolean column that indicates, which rows were missing.  Implementation is pretty much taken from fastai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FillStrategy:\n",
    "    \"Namespace containing the various filling strategies.\"\n",
    "    def median  (c,fill): return c.median()\n",
    "    def constant(c,fill): return fill\n",
    "    def mode    (c,fill): return c.dropna().value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FillMissing(PPProc):\n",
    "    order=1\n",
    "    \"Fill the missing values in continuous columns.\"\n",
    "    def __init__(self, fill_strategy=FillStrategy.median, add_col=True, fill_vals=None):\n",
    "        if fill_vals is None: fill_vals = defaultdict(int)\n",
    "        store_attr()\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        missing = pd.isnull(dsets.conts).any()\n",
    "        store_attr(but='to', na_dict={n:self.fill_strategy(dsets[n], self.fill_vals[n])\n",
    "                            for n in missing[missing].keys()})\n",
    "        self.fill_strategy = self.fill_strategy.__name__\n",
    "\n",
    "    def encodes(self, to):\n",
    "        missing = pd.isnull(to.conts)\n",
    "        for n in missing.any()[missing.any()].keys():\n",
    "            assert n in self.na_dict, f\"nan values in `{n}` but not in setup training set\"\n",
    "        for n in self.na_dict.keys():\n",
    "            to[n].fillna(self.na_dict[n], inplace=True)\n",
    "            if self.add_col:\n",
    "                to.loc[:,n+'_na'] = missing[n]\n",
    "                if n+'_na' not in to.cat_names: to.cat_names.append(n+'_na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 7 #events: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_na</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fill = FillMissing() \n",
    "df = pd.DataFrame({'a':[0,1,np.nan,1,2,3,4], 'b': [0,1,2,3,4,5,6]})\n",
    "to = PPObj(df, fill, cont_names=['a', 'b'])\n",
    "to.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates standartization, also known as z-score formula. Copied from fastai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Normalize(PPProc):\n",
    "    \"Normalize with z-score\"\n",
    "    order = 3\n",
    "    def setups(self, to):\n",
    "        store_attr(but='to', means=dict(getattr(to, 'train', to).conts.mean()),\n",
    "                   stds=dict(getattr(to, 'train', to).conts.std(ddof=0)+1e-7))\n",
    "        return self(to)\n",
    "\n",
    "    def encodes(self, to): to.conts = (to.conts-self.means) / self.stds\n",
    "    def decodes(self, to): to.conts = (to.conts*self.stds ) + self.means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 5 #events: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.429409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.327783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.514775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'a':[0,1,9,3,4]})\n",
    "to = PPObj(df, Normalize(), cont_names='a')\n",
    "to.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodes a date column. Supports multiple information by using pandas date functions. This implementation is also based on the fastai but also supports relative duration from the first event of a case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _make_date(df, date_field):\n",
    "    \"Make sure `df[date_field]` is of the right date type.\"\n",
    "    field_dtype = df[date_field].dtype\n",
    "    if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "        field_dtype = np.datetime64\n",
    "    if not np.issubdtype(field_dtype, np.datetime64):\n",
    "        df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True,utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fu    datetime64[ns, UTC]\n",
       "dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'fu': ['2019-12-04', '2019-11-29', '2019-11-15', '2019-10-24']})\n",
    "_make_date(df, 'fu')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _secSinceSunNoon(datTimStr):\n",
    "    dt = pd.to_datetime(datTimStr).dt\n",
    "    return (dt.dayofweek-1)*24*3600+ dt.hour * 3600 + dt.minute * 60 + dt.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _secSinceNoon(datTimStr):\n",
    "    dt = pd.to_datetime(datTimStr).dt\n",
    "    return dt.hour * 3600 + dt.minute * 60 + dt.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "Base_Date_Encodings=['Year', 'Month', 'Day', 'Dayofweek', 'Dayofyear','Elapsed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def encode_date(df, field_name,unit=1e9,date_encodings=Base_Date_Encodings):\n",
    "    \"Helper function that adds columns relevant to a date in the column `field_name` of `df`.\"\n",
    "    _make_date(df, field_name)\n",
    "    field = df[field_name]\n",
    "    prefix =  re.sub('[Dd]ate$', '', field_name+\"_\")\n",
    "    attr = ['Year', 'Month', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',\n",
    "            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "    if time: attr = attr + ['Hour', 'Minute', 'Second']\n",
    "    for n in attr:\n",
    "        if n in date_encodings: df[prefix + n] = getattr(field.dt, n.lower())\n",
    "    # Pandas removed `dt.week` in v1.1.10\n",
    "\n",
    "    if 'secSinceSunNoon' in date_encodings:\n",
    "        df[prefix+'secSinceSunNoon']=_secSinceSunNoon(field)\n",
    "    if 'secSinceNoon' in date_encodings:\n",
    "        df[prefix+'secSinceNoon']=_secSinceNoon(field)\n",
    "    if 'Week' in date_encodings:\n",
    "        week = field.dt.isocalendar().week if hasattr(field.dt, 'isocalendar') else field.dt.week\n",
    "        df.insert(3, prefix+'Week', week)\n",
    "    mask = ~field.isna()\n",
    "    elapsed = pd.Series(np.where(mask,field.values.astype(np.int64) // unit,None).astype(float),index=field.index)\n",
    "\n",
    "    if 'Relative_elapsed' in date_encodings:\n",
    "        df[prefix+'Relative_elapsed']=elapsed-elapsed.groupby(elapsed.index).transform('min')\n",
    "\n",
    "    # required to decode!\n",
    "    if 'Elapsed' in date_encodings: df[prefix+'Elapsed']=elapsed\n",
    "\n",
    "    df.drop(field_name, axis=1, inplace=True)\n",
    "    return [],[prefix+i for i in date_encodings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fu_Year</th>\n",
       "      <th>fu_Month</th>\n",
       "      <th>fu_Day</th>\n",
       "      <th>fu_Dayofweek</th>\n",
       "      <th>fu_Dayofyear</th>\n",
       "      <th>fu_Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>338</td>\n",
       "      <td>1.575418e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>333</td>\n",
       "      <td>1.574986e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>319</td>\n",
       "      <td>1.573776e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>297</td>\n",
       "      <td>1.571875e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fu_Year  fu_Month  fu_Day  fu_Dayofweek  fu_Dayofyear    fu_Elapsed\n",
       "0     2019        12       4             2           338  1.575418e+09\n",
       "1     2019        11      29             4           333  1.574986e+09\n",
       "2     2019        11      15             4           319  1.573776e+09\n",
       "3     2019        10      24             3           297  1.571875e+09"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'fu': ['2019-12-04', '2019-11-29', '2019-11-15', '2019-10-24']})\n",
    "encode_date(df,'fu')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def decode_date(df, field_name,unit=1e9,date_encodings=Base_Date_Encodings):\n",
    "    df[field_name]=(df[field_name+'_'+'Elapsed'] * unit).astype('datetime64[ns, UTC]')\n",
    "    for c in date_encodings: del df[field_name+'_'+c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-04 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-29 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-15 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-24 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         fu\n",
       "0 2019-12-04 00:00:00+00:00\n",
       "1 2019-11-29 00:00:00+00:00\n",
       "2 2019-11-15 00:00:00+00:00\n",
       "3 2019-10-24 00:00:00+00:00"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_date(df,'fu')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Datetify(PPProc):\n",
    "    \"Encode dates, \"\n",
    "    order = 0\n",
    "\n",
    "    def __init__(self, date_encodings=['Relative_elapsed']): self.date_encodings=listify(date_encodings)\n",
    "\n",
    "    def encodes(self, o):\n",
    "        for i in o.date_names:\n",
    "            cat,cont=encode_date(o.items,i,date_encodings=self.date_encodings)\n",
    "            o.cont_names+=cont\n",
    "            o.cat_names+=cat\n",
    "# Todo: Add decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fu_secSinceSunNoon</th>\n",
       "      <th>fu_secSinceNoon</th>\n",
       "      <th>fu_Relative_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86400</td>\n",
       "      <td>0</td>\n",
       "      <td>432000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>950400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172800</td>\n",
       "      <td>0</td>\n",
       "      <td>1728000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fu_secSinceSunNoon  fu_secSinceNoon  fu_Relative_elapsed\n",
       "1              259200                0                  0.0\n",
       "1               86400                0             432000.0\n",
       "1                   0                0             950400.0\n",
       "1              172800                0            1728000.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'fu': ['2019-10-04', '2019-10-09', '2019-10-15', '2019-10-24']},index=[1,1,1,1])\n",
    "o = PPObj(df,Datetify(date_encodings=['secSinceSunNoon','secSinceNoon','Relative_elapsed']),date_names='fu')\n",
    "o.xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMax Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the MinMax scaling from a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MinMax(PPProc):\n",
    "    order=3\n",
    "\n",
    "    def setups(self, o):\n",
    "        store_attr(mins=o.xs.min(),\n",
    "                   maxs=o.xs.max())\n",
    "\n",
    "    def encodes(self, o):\n",
    "        cols=[i+'_minmax' for i in o.x_names]\n",
    "        o[cols] = o.xs.astype(float)\n",
    "        o[cols] = ((o.xs-self.mins) /(self.maxs-self.mins))\n",
    "        o.cont_names=L(cols)\n",
    "        o.cat_names=L()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One HoT Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the one-hot encoding of a column. It is required to first apply categorization on the same column, to deal with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=PPObj(log,[Categorify],cat_names=['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289892, 74)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(o.xs),len(o.procs.categorify['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73],\n",
       "       [10],\n",
       "       [ 7],\n",
       "       ...,\n",
       "       [ 5],\n",
       "       [53],\n",
       "       [72]], dtype=int8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.xs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=o.xs.to_numpy()\n",
    "categories=[range(len(o.procs.categorify['activity'])),range(len(o.procs.categorify['activity']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(['a1','a2'])\n",
    "categories=[['a1','a2','a3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(categories=categories)\n",
    "a=ohe.fit_transform(x.reshape(-1, 1)).toarray()\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['a1','a2','a3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OneHot(PPProc):\n",
    "    \"Transform the categorical variables to one-hot. Requires Categorify to deal with unseen data.\"\n",
    "    order = 3\n",
    "\n",
    "    def encodes(self, o):\n",
    "        new_cats=[]\n",
    "        for c in o.cat_names:\n",
    "            categories=[range(len(o.procs.categorify[c]))]\n",
    "            x=o[c].to_numpy()\n",
    "            ohe = OneHotEncoder(categories=categories)\n",
    "            enc=ohe.fit_transform(x.reshape(-1, 1)).toarray()\n",
    "            for i in range(enc.shape[1]):\n",
    "                new_cat=f'{c}_{i}'\n",
    "                o.items.loc[:,new_cat]=enc[:,i]\n",
    "                new_cats.append(new_cat)\n",
    "        o.cat_names=L(new_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df=import_log('data/csv/PDC2021_training/pdc2021_0000000.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.8 ms, sys: 6.56 ms, total: 32.3 ms\n",
      "Wall time: 31.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "o=PPObj(event_df,[Categorify(),OneHot()],cat_names=['activity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we cover the sliding window generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _shift_columns (a,ws=3): return np.dstack(list(reversed([np.roll(a,i) for i in range(0,ws)])))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def windows_fast(df,event_ids,ws=5,pad=None):\n",
    "    max_trace_len=int(event_ids.max())+1\n",
    "    trace_start = np.where(event_ids == 0)[0]\n",
    "    trace_len=[trace_start[i]-trace_start[i-1] for i in range(1,len(trace_start))]+[len(df)-trace_start[-1]]\n",
    "    idx=[range(trace_start[i]+(i+1)\n",
    "               *(ws-1),trace_start[i]+trace_len[i]+(i+1)*(ws-1)-1) for i in range(len(trace_start))]\n",
    "    idx=np.array([y for x in idx for y in x])\n",
    "    trace_start = np.repeat(trace_start, ws-1)\n",
    "    tmp=np.stack([_shift_columns(np.insert(np.array(df[i]), trace_start, 0, axis=0),ws=ws) for i in list(df)]) \n",
    "    tmp=np.rollaxis(tmp,1) \n",
    "    res=tmp[idx]\n",
    "    if pad: res=np.pad(res,((0,0),(0,0),(pad-ws,0))) \n",
    "    \n",
    "    return res,np.where(event_ids != 0)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df=import_log('data/csv/PDC2020_ground_truth/pdc_2020_0000000.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o=PPObj(event_df,Categorify(),cat_names=['activity'],y_names='activity')\n",
    "#o=o.iloc[0]\n",
    "len(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17029"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(o.items)-len(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0,  0,  0,  0,  2]],\n",
       " \n",
       "        [[ 0,  0,  0,  2,  3]],\n",
       " \n",
       "        [[ 0,  0,  2,  3,  4]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[12, 15, 18, 19, 21]],\n",
       " \n",
       "        [[15, 18, 19, 21, 20]],\n",
       " \n",
       "        [[18, 19, 21, 20, 22]]], dtype=int8),\n",
       " (17029, 1, 5))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws,idx=windows_fast(o.xs,o.event_ids,ws=5)\n",
    "ws,ws.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prefixes are converted to a `pytorch.Dataset` and than to a `DataLoader`\n",
    "A batch is than represented as a tuple of the form `(x cat. attr,x cont. attr, y cat. attr., y cont attr.)`. Also, categorical attributes are converted to a long tensor and continous attributes to a float tensor.\n",
    "\n",
    "If a dimensions of the batch is empty - e.g. the model does not use categorical input attributes - it is removed from the tuple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0,  0,  0, ...,  0,  0,  2]],\n",
       " \n",
       "        [[ 0,  0,  0, ...,  0,  2,  3]],\n",
       " \n",
       "        [[ 0,  0,  0, ...,  2,  3,  4]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[11, 13,  6, ..., 18, 19, 21]],\n",
       " \n",
       "        [[13,  6, 10, ..., 19, 21, 20]],\n",
       " \n",
       "        [[ 6, 10, 16, ..., 21, 20, 22]]], dtype=int8),\n",
       " (17029, 1, 10))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o=PPObj(event_df,Categorify(),cat_names=['activity'],y_names='activity')\n",
    "ws,idx=windows_fast(o.xs,o.event_ids,ws=10)\n",
    "ws,ws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11], dtype=int8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.ys.iloc[idx].values[16765]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.ys.groupby(o.items.index).transform('last').iloc[idx].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not outcome: y=o.ys.iloc[idx]\n",
    "else: y=o.ys.groupby(o.items.index).transform('last').iloc[idx]\n",
    "ycats=tensor(y[o.ycat_names].values).long()\n",
    "yconts=tensor(y[o.ycont_names].values).float()\n",
    "xcats=tensor(ws[:,len(o.cat_names):]).float()\n",
    "xconts=tensor(ws[:,:len(o.cat_names)]).long()\n",
    "xs=tuple([i for i in [xcats,xconts] if i.shape[1]>0])\n",
    "ys=tuple([ycats[:,i] for i in range(ycats.shape[1])])+tuple([yconts[:,i] for i in range(yconts.shape[1])])\n",
    "res=(*xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3,  4,  5,  ..., 20, 22,  1]),)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PPDset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inp):\n",
    "        store_attr('inp')\n",
    "\n",
    "    def __len__(self): return len(self.inp[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        xs=tuple([i[idx]for i in self.inp[:-1]])\n",
    "        ys=tuple([i[idx]for i in self.inp[-1]])\n",
    "        #if len(ys)==1: ys=ys[0]\n",
    "        return (*xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls=DataLoaders.from_dsets(PPDset(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 10]), torch.Size([64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xcat,y=dls.one_batch()\n",
    "xcat.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=PPObj(event_df,Categorify(),cat_names=['activity'],y_names='activity',splits=split_traces(event_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) ['activity']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(TfmdDL)\n",
    "def get_dls(ppo:PPObj,windows=windows_fast,outcome=False,event_id='event_id',bs=64,**kwargs):\n",
    "    ds=[]\n",
    "    for s in ppo.subsets():\n",
    "        wds,idx=windows(s.xs,s.event_ids)\n",
    "\n",
    "        if not outcome: y=s.ys.iloc[idx]\n",
    "        else: y=s.ys.groupby(s.items.index).transform('last').iloc[idx]\n",
    "        ycats=tensor(y[s.ycat_names].values).long()\n",
    "        yconts=tensor(y[s.ycont_names].values).float()\n",
    "        xconts=tensor(wds[:,len(s.cat_names):]).float()\n",
    "        xcats=tensor(wds[:,:len(s.cat_names)]).long()\n",
    "        xs=tuple([i for i in [xcats,xconts] if i.shape[1]>0])\n",
    "        ys=tuple([ycats[:,i] for i in range(ycats.shape[1])])+tuple([yconts[:,i] for i in range(yconts.shape[1])])\n",
    "        ds.append(PPDset((*xs,ys)))\n",
    "    return DataLoaders.from_dsets(*ds,bs=bs,device=torch.device('cuda'),**kwargs)\n",
    "PPObj.get_dls= get_dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 5]), torch.Size([64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls=o.get_dls()\n",
    "xb,yb=dls.one_batch()\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section shows, how the PPObj can be used to create a DataLoader for pedictive process analytics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next event prediction:  \n",
    "X: 'activity'   \n",
    "Y: 'activity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 1000 #events: 18029\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trace 835</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace 835</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 2]), torch.Size([64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log=import_log('data/csv/PDC2020_ground_truth/pdc_2020_0000001.csv.gz')\n",
    "o=PPObj(log,Categorify(),cat_names=['activity'],y_names='activity',splits=split_traces(event_df))\n",
    "dls=o.get_dls(windows=partial(windows_fast,ws=2))\n",
    "o.show(max_n=2)\n",
    "xb,y=dls.one_batch()\n",
    "xb.shape,y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All of this code was to create a pipeline called PPObj to take an event log, split it to train,test,val and preprocess the data in an orginized manner."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dapnn",
   "language": "python",
   "name": "dapnn"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
